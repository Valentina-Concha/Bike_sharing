{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bddf9d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#NUEVOO CODIGO QUE AGREGA LA COLUMNA \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#pandas es una biblioteca Python para manipular y analizar datos sobre todo df, especialmente archivos como Excel.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#openpyxl es una biblioteca que permite trabajar directamente con archivos Excel. Aquí se usa para cargar y actualizar el archivo existente.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#NUEVOO CODIGO QUE AGREGA LA COLUMNA \n",
    "#pandas es una biblioteca Python para manipular y analizar datos sobre todo df, especialmente archivos como Excel.\n",
    "import pandas as pd\n",
    "#openpyxl es una biblioteca que permite trabajar directamente con archivos Excel. Aquí se usa para cargar y actualizar el archivo existente.\n",
    "from openpyxl import load_workbook\n",
    "#para importar los datos de bicicletas de py\n",
    "#los datos que entrega en los links de la web son tipo json\n",
    "import pybikes\n",
    "#para exportar la fecha actual de hoy\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "#import requests: Se importa la librería requests, que se utiliza para realizar peticiones HTTP en Python. Esto permite acceder a datos de APIs (interfaces de programación de aplicaciones) que suelen ofrecer información en formato JSON.\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "#station_info_url: Esta variable almacena la URL que proporciona información sobre las estaciones de bicicletas, como nombre, capacidad y ubicación.\n",
    "#station_status_url: Esta variable almacena la URL que proporciona el estado actual de las estaciones, incluyendo la disponibilidad de bicicletas y espacios.\n",
    "# URL de la API de información de estaciones\n",
    "station_info_url = 'https://santiago.publicbikesystem.net/customer/ube/gbfs/v1/en/station_information'\n",
    "\n",
    "# URL de la API de estado de estaciones\n",
    "station_status_url = 'https://santiago.publicbikesystem.net/customer/ube/gbfs/v1/en/station_status'\n",
    "\n",
    "# Hacer las solicitudes GET\n",
    "#Se realizan dos solicitudes HTTP GET a las URLs definidas anteriormente. Estas solicitudes recuperan datos de las APIs.\n",
    "station_info_response = requests.get(station_info_url)\n",
    "station_status_response = requests.get(station_status_url)\n",
    "\n",
    "\n",
    "# Verificar si ambas solicitudes fueron exitosas. Aquí se comprueba si ambas solicitudes fueron exitosas (código de estado 200 significa que la solicitud fue exitosa)\n",
    "if station_info_response.status_code == 200 and station_status_response.status_code == 200:\n",
    "    #Cargar los datos de las respuestas en formato JSON. Si las solicitudes fueron exitosas, los datos se cargan en formato JSON a las variables correspondientes (station_info_data y station_status_data)\n",
    "    station_info_data = station_info_response.json()\n",
    "    station_status_data = station_status_response.json()\n",
    "    \n",
    "    # Listas para almacenar los datos. Se inicializan listas vacías para almacenar los datos de cada estación que se extraerán del JSON.\n",
    "    estaciones = []\n",
    "    grupos = []\n",
    "    capacidad = []\n",
    "    latitud = []\n",
    "    longitud = []\n",
    "    bikes = []\n",
    "    free = []\n",
    "    num_bikes_disabled = []\n",
    "    fechas = []  # Lista para almacenar la fecha\n",
    "    horas = []   # Lista para almacenar la hora\n",
    "\n",
    "    # Obtener la fecha y la hora actuales\n",
    "    fecha_actual = date.today()\n",
    "    hora_actual = datetime.now()\n",
    "\n",
    "    # Obtener información de estaciones\n",
    "    #stations_info: Extrae la información sobre las estaciones desde los datos JSON.\n",
    "    #Ciclo for: Itera sobre cada estación en stations_info para extraer los detalles.\n",
    "    #station.get('station_id', 'Unknown ID'): Intenta obtener el station_id. Si no está disponible, se asigna el valor 'Unknown ID'. Por esto puse \"Unknown\", es una forma de manejar posibles valores faltantes o no disponibles.\n",
    "    #Se obtienen otras propiedades de la estación (nombre, grupos, capacidad, latitud y longitud) de manera similar, utilizando valores por defecto en caso de que falten.\n",
    "    stations_info = station_info_data.get('data', {}).get('stations', [])\n",
    "    \n",
    "    for station in stations_info:\n",
    "        station_id = station.get('station_id', 'Unknown ID')\n",
    "        estaciones.append(station.get('name', 'Unknown Station'))\n",
    "        grupos.append(station.get('groups', ['Sin grupo'])[0])  # Si no hay grupo, colocar 'Sin grupo'\n",
    "        capacidad.append(station.get('capacity', 'Unknown Capacity'))\n",
    "        latitud.append(station.get('lat', 'Unknown Latitude'))\n",
    "        longitud.append(station.get('lon', 'Unknown Longitude'))\n",
    "        fechas.append(fecha_actual)  # Agregar la fecha a cada fila\n",
    "        horas.append(hora_actual)    # Agregar la hora a cada fila\n",
    "    \n",
    "    # Obtener estado de estaciones\n",
    "    #Se repite un proceso similar para el estado de las estaciones:\n",
    "    #stations_status: Extrae los datos de estado desde el JSON.\n",
    "    #status_dict: Se crea un diccionario que relaciona cada station_id con su estado.\n",
    "    #Luego se extraen datos sobre el número de bicicletas disponibles, espacios libres y bicicletas deshabilitadas, utilizando el mismo enfoque de valores por defecto.\n",
    "    stations_status = station_status_data.get('data', {}).get('stations', [])\n",
    "    \n",
    "    #Crear un diccionario para relacionar 'station_id' con los datos de estado\n",
    "    #Se repite un proceso similar para el estado de las estaciones:\n",
    "    #stations_status: Extrae los datos de estado desde el JSON.\n",
    "    #status_dict: Se crea un diccionario que relaciona cada station_id con su estado.\n",
    "    #Luego se extraen datos sobre el número de bicicletas disponibles, espacios libres y bicicletas deshabilitadas, utilizando el mismo enfoque de valores por defecto.\n",
    "    status_dict = {station.get('station_id'): station for station in stations_status}\n",
    "    \n",
    "    for station in stations_info:\n",
    "        station_id = station.get('station_id', 'Unknown ID')\n",
    "        status = status_dict.get(station_id, {})\n",
    "        bikes.append(status.get('num_bikes_available', 'Unknown Bikes'))\n",
    "        free.append(status.get('num_docks_available', 'Unknown Free'))\n",
    "        num_bikes_disabled.append(status.get('num_bikes_disabled', 'Unknown Disabled'))\n",
    "    \n",
    "    # Crear el DataFrame final con todas las columnas necesarias\n",
    "    df = pd.DataFrame({\n",
    "        'Estacion': estaciones,\n",
    "        'Comuna': grupos,\n",
    "        'Capacidad (Slots)': capacidad,\n",
    "        'Latitud': latitud,\n",
    "        'Longitud': longitud,\n",
    "        'Bikes disponibles': bikes,\n",
    "        'Free': free,\n",
    "        'Bikes Deshabilitadas': num_bikes_disabled,\n",
    "        'Fecha': fechas,  # Agregar la columna Fecha\n",
    "        'Hora': horas     # Agregar la columna Hora\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Mostrar en Python el número total de estaciones descargadas\n",
    "    total_estaciones = len(stations_info)\n",
    "    print(f\"Número total de estaciones descargadas: {total_estaciones}\")\n",
    "    \n",
    "    # Si quieres asegurarte de que se descargaron ambas listas de datos correctamente\n",
    "    print(f\"Número de estaciones en la información de estaciones: {len(stations_info)}\")\n",
    "    print(f\"Número de estaciones en el estado de estaciones: {len(stations_status)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error en las solicitudes: {station_info_response.status_code}, {station_status_response.status_code}\")\n",
    "print(df)\n",
    "\n",
    "#GUARDA LOS DATOS EN BD DENTRO DEL MISMO EXCEL\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Definir el nombre del archivo\n",
    "file_name = 'C:/Users/VALE/Desktop/Tesis/Tesis Pedro Palominos/Código python/Ejemplo228-28-09.xlsx'\n",
    "\n",
    "# Crear el DataFrame (puedes usar tu propio DataFrame aquí)\n",
    "# df_data_countries = pd.DataFrame({\"Columna1\": [5, 6], \"Columna2\": [7, 8]})\n",
    "\n",
    "# Definir el nombre de la hoja donde vas a escribir\n",
    "sheet_name = 'BD2'\n",
    "\n",
    "# Cargar el archivo de Excel existente\n",
    "book = load_workbook(file_name)\n",
    "if sheet_name in book.sheetnames:\n",
    "    # Cargar los datos existentes de la hoja especificada en un DataFrame\n",
    "    existing_df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "    \n",
    "    # Eliminar cualquier columna completamente vacía, para que no se agreguen columnas como Unnamed: 1, 2..\n",
    "    existing_df = existing_df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Agregar los nuevos datos al final del DataFrame existente\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    \n",
    "    # Guardar el DataFrame actualizado en la misma hoja, sobrescribiéndola\n",
    "    with pd.ExcelWriter(file_name, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        updated_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "else:\n",
    "    # Si la hoja no existe, escribir el DataFrame desde cero\n",
    "    with pd.ExcelWriter(file_name, engine='openpyxl', mode='a') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Datos exportados a {file_name} en la hoja '{sheet_name}'\")\n",
    "\n",
    "\n",
    "\n",
    "#ESTA PARTE ENTREGA EL DF CON LAS VARIANZAS, SIMETRIA, CURTOSIS Y SUS PROMEDIOS DE BIKES Y DE FREE\n",
    "#incluye kurtosis, simetria  y calculo de varianzas bikes y free, también los promedios\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Nombre del archivo y hoja original\n",
    "file_name = 'C:/Users/VALE/Desktop/Tesis/Tesis Pedro Palominos/Código python/Ejemplo228-28-09.xlsx'\n",
    "sheet_name = 'BD2'\n",
    "\n",
    "# Leer el archivo de Excel en un DataFrame\n",
    "df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "\n",
    "# Calcular la varianza de las columnas \"Bikes disponibles\" y \"Free\" por estación\n",
    "varianza_bikes = df.groupby('Estacion')['Bikes disponibles'].var().reset_index(name='Varianza_Bikes')\n",
    "varianza_free = df.groupby('Estacion')['Free'].var().reset_index(name='Varianza_Free')\n",
    "\n",
    "# Hacer merge para incluir las varianzas en el DataFrame original\n",
    "df_varianza = pd.merge(varianza_bikes, varianza_free, on='Estacion')\n",
    "\n",
    "# Unir con el DataFrame original para obtener la columna 'Comuna'\n",
    "df_varianza = df_varianza.merge(df[['Estacion', 'Comuna']].drop_duplicates(), on='Estacion', how='left')\n",
    "\n",
    "# Calcular el promedio de la varianza por comuna (promediar las varianzas por estación dentro de cada comuna)\n",
    "varianza_comuna_bikes = df_varianza.groupby('Comuna')['Varianza_Bikes'].mean().reset_index(name='Varianza_Bikes_Promedio')\n",
    "varianza_comuna_free = df_varianza.groupby('Comuna')['Varianza_Free'].mean().reset_index(name='Varianza_Free_Promedio')\n",
    "\n",
    "# Unir los resultados de las varianzas promedio por comuna con el DataFrame original\n",
    "df_varianza = pd.merge(df_varianza, varianza_comuna_bikes, on='Comuna', how='left')\n",
    "df_varianza = pd.merge(df_varianza, varianza_comuna_free, on='Comuna', how='left')\n",
    "\n",
    "# Calcular la simetría y la curtosis para cada estación\n",
    "df_varianza['Simetria_Bikes'] = df.groupby('Estacion')['Bikes disponibles'].apply(lambda x: skew(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Curtosis_Bikes'] = df.groupby('Estacion')['Bikes disponibles'].apply(lambda x: kurtosis(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Simetria_Free'] = df.groupby('Estacion')['Free'].apply(lambda x: skew(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Curtosis_Free'] = df.groupby('Estacion')['Free'].apply(lambda x: kurtosis(x, bias=False)).reset_index(drop=True)\n",
    "\n",
    "# Calcular la simetría y curtosis promedio por comuna\n",
    "simetria_comuna_bikes = df_varianza.groupby('Comuna')['Simetria_Bikes'].mean().reset_index(name='Simetria_Bikes_Promedio')\n",
    "curtosis_comuna_bikes = df_varianza.groupby('Comuna')['Curtosis_Bikes'].mean().reset_index(name='Curtosis_Bikes_Promedio')\n",
    "\n",
    "simetria_comuna_free = df_varianza.groupby('Comuna')['Simetria_Free'].mean().reset_index(name='Simetria_Free_Promedio')\n",
    "curtosis_comuna_free = df_varianza.groupby('Comuna')['Curtosis_Free'].mean().reset_index(name='Curtosis_Free_Promedio')\n",
    "\n",
    "# Unir los resultados de simetría y curtosis promedio por comuna con el DataFrame original\n",
    "df_varianza = pd.merge(df_varianza, simetria_comuna_bikes, on='Comuna', how='left')\n",
    "df_varianza = pd.merge(df_varianza, curtosis_comuna_bikes, on='Comuna', how='left')\n",
    "df_varianza = pd.merge(df_varianza, simetria_comuna_free, on='Comuna', how='left')\n",
    "df_varianza = pd.merge(df_varianza, curtosis_comuna_free, on='Comuna', how='left')\n",
    "\n",
    "# Cargar el libro de Excel existente\n",
    "book = load_workbook(file_name)\n",
    "\n",
    "# Generar un nombre único para la nueva hoja, usando la fecha y hora actual\n",
    "timestamp = datetime.now().strftime('%H%M')\n",
    "new_sheet_name = f'VKSPromCom {timestamp}'\n",
    "\n",
    "# Escribir el resultado de las varianzas, simetría y curtosis en una nueva hoja\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl', mode='a') as writer:\n",
    "    df_varianza.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Varianza, Simetría, Curtosis, y la varianza, simetría y curtosis promedio por comunas calculadas y guardadas en la nueva hoja '{new_sheet_name}'.\")\n",
    "\n",
    "\n",
    "#ENTREGA EN UNA HOJA NUEVA DE EXCEL EL RESUMEN DE TODOS LOS ESTADISTICOS PROMEDIOS\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Nombre del archivo y hoja original\n",
    "file_name = 'C:/Users/VALE/Desktop/Tesis/Tesis Pedro Palominos/Código python/Ejemplo228-28-09.xlsx'\n",
    "sheet_name = 'BD2'\n",
    "\n",
    "# Leer el archivo de Excel en un DataFrame\n",
    "df = pd.read_excel(file_name, sheet_name=sheet_name)\n",
    "\n",
    "# Calcular la varianza de las columnas \"Bikes disponibles\" y \"Free\" agrupadas por Estación\n",
    "varianza_bikes = df.groupby('Estacion')['Bikes disponibles'].var().reset_index(name='Varianza_Bikes')\n",
    "varianza_free = df.groupby('Estacion')['Free'].var().reset_index(name='Varianza_Free')\n",
    "\n",
    "# Hacer merge para incluir la columna 'Comuna' correspondiente\n",
    "df_varianza = pd.merge(varianza_bikes, varianza_free, on='Estacion')\n",
    "df_varianza = df_varianza.merge(df[['Estacion', 'Comuna']].drop_duplicates(), on='Estacion', how='left')\n",
    "\n",
    "# Calcular el promedio de la varianza por comuna\n",
    "varianza_comuna_bikes = df_varianza.groupby('Comuna')['Varianza_Bikes'].mean().reset_index(name='Varianza_Bikes_Promedio')\n",
    "varianza_comuna_free = df_varianza.groupby('Comuna')['Varianza_Free'].mean().reset_index(name='Varianza_Free_Promedio')\n",
    "\n",
    "# Calcular simetría y curtosis por estación\n",
    "df_varianza['Simetria_Bikes'] = df.groupby('Estacion')['Bikes disponibles'].apply(lambda x: skew(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Curtosis_Bikes'] = df.groupby('Estacion')['Bikes disponibles'].apply(lambda x: kurtosis(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Simetria_Free'] = df.groupby('Estacion')['Free'].apply(lambda x: skew(x, bias=False)).reset_index(drop=True)\n",
    "df_varianza['Curtosis_Free'] = df.groupby('Estacion')['Free'].apply(lambda x: kurtosis(x, bias=False)).reset_index(drop=True)\n",
    "\n",
    "# Calcular el promedio de la simetría y curtosis por comuna\n",
    "simetria_comuna_bikes = df_varianza.groupby('Comuna')['Simetria_Bikes'].mean().reset_index(name='Simetria_Bikes_Promedio')\n",
    "curtosis_comuna_bikes = df_varianza.groupby('Comuna')['Curtosis_Bikes'].mean().reset_index(name='Curtosis_Bikes_Promedio')\n",
    "simetria_comuna_free = df_varianza.groupby('Comuna')['Simetria_Free'].mean().reset_index(name='Simetria_Free_Promedio')\n",
    "curtosis_comuna_free = df_varianza.groupby('Comuna')['Curtosis_Free'].mean().reset_index(name='Curtosis_Free_Promedio')\n",
    "\n",
    "# Combinar los resultados de varianzas, simetría y curtosis en un DataFrame final\n",
    "df_varianza_comuna = pd.merge(varianza_comuna_bikes, varianza_comuna_free, on='Comuna')\n",
    "df_varianza_comuna = pd.merge(df_varianza_comuna, simetria_comuna_bikes, on='Comuna')\n",
    "df_varianza_comuna = pd.merge(df_varianza_comuna, curtosis_comuna_bikes, on='Comuna')\n",
    "df_varianza_comuna = pd.merge(df_varianza_comuna, simetria_comuna_free, on='Comuna')\n",
    "df_varianza_comuna = pd.merge(df_varianza_comuna, curtosis_comuna_free, on='Comuna')\n",
    "\n",
    "# Cargar el libro de Excel existente\n",
    "book = load_workbook(file_name)\n",
    "\n",
    "# Generar un nombre único para la nueva hoja, usando la fecha y hora actual\n",
    "timestamp = datetime.now().strftime('%H%M%S')\n",
    "new_sheet_name = f'Varianza_Comuna_Promedio {timestamp}'\n",
    "\n",
    "# Escribir el resultado de las varianzas, simetría y curtosis por comuna en una nueva hoja\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl', mode='a') as writer:\n",
    "    df_varianza_comuna.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "print(f\"Varianza, Simetría y Curtosis promedio de 'Bikes' y 'Free' por comuna calculadas y guardadas en la nueva hoja '{new_sheet_name}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
